{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n",
      "Key number:  27\n",
      "Escape hit, closing...\n"
     ]
    }
   ],
   "source": [
    "# Here is a simple program that displays the camera feed in a cv2.namedWindow and will save images inside bounding box when 'c' is pressed on keyboard. \n",
    "# It will also quit if you hit ESC.\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from keras.models import load_model, model_from_json\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import time\n",
    "import win32com.client as wincl\n",
    "import time\n",
    "\n",
    "#speak.Speak(\"Okay Google esta bien google que tiempo hace hoy\")\n",
    "\n",
    "# dimensions of our images\n",
    "image_x, image_y = 64, 64\n",
    "speak = wincl.Dispatch(\"SAPI.SpVoice\")\n",
    "\n",
    "cam = cv2.VideoCapture(1)\n",
    "if cam.read()[0]==False:\n",
    "    cam = cv2.VideoCapture(0)\n",
    "#Prediction Classes\n",
    "gesture_list = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','OK GOOGLE','P','Q','R','S','SPACE','T','U','V','W','X','Y','Z']\n",
    "\n",
    "def get_bounding_box(img):\n",
    "    x, y, w, h = 420, 140, 200, 200\n",
    "    cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 3)\n",
    "    \n",
    "def get_cropped_image(img):\n",
    "    x, y, w, h = 420, 140, 200, 200\n",
    "#     cv2.rectangle(img, (x,y), (x+w, y+h), (0,255,0), 3)\n",
    "    imgCrop = img[y:y+h, x:x+w]\n",
    "    return imgCrop\n",
    "\n",
    "def process_image(img):\n",
    "    # clone the frame\n",
    "    clone = img.copy()\n",
    "    # convert to grayscale\n",
    "    grey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # applying gaussian blur\n",
    "    value = (1, 1)\n",
    "    blurred = cv2.GaussianBlur(grey, value, 0)\n",
    "\n",
    "    # thresholdin: Otsu's Binarization method\n",
    "    _, thresh = cv2.threshold(blurred, 127, 255,\n",
    "                               cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    # Convert to 3 Channels\n",
    "    thresh = cv2.cvtColor(thresh, cv2.COLOR_GRAY2RGB)\n",
    "    return thresh\n",
    "def load_new_model():\n",
    "    # load json and create model\n",
    "    json_file = open('model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(\"model.h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "    return loaded_model\n",
    "\n",
    "def get_prediction(img,loaded_model):\n",
    "    loaded_model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    \n",
    "    images = np.vstack([x])\n",
    "    classes = loaded_model.predict_classes(images, batch_size=10)\n",
    "    prediction = gesture_list[int(classes)]\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "sent = []\n",
    "\n",
    "def start_camera(loaded_model):\n",
    "    frames=0\n",
    "    while True:\n",
    "        img = cam.read()[1]\n",
    "        img = cv2.flip(img, 1)\n",
    "        img_cropped = get_cropped_image(img)\n",
    "        processed_img = process_image(img_cropped)\n",
    "        # make a PIL image\n",
    "        to_predict = Image.fromarray(processed_img)\n",
    "        to_predict = to_predict.resize((64,64))\n",
    "        if frames>10:\n",
    "            try:\n",
    "                pred = get_prediction(to_predict,loaded_model)\n",
    "                cv2.putText(img, pred, (30, 60), cv2.FONT_HERSHEY_TRIPLEX, 2, (127, 255, 255))\n",
    "                sent.append(pred)\n",
    "                \n",
    "            except Exception as e:\n",
    "                pred = \"--\"\n",
    "                print(\"Something Happened :\",e)\n",
    "                break\n",
    "        \n",
    "        get_bounding_box(img)\n",
    "        cv2.imshow(\"Capturing gesture\", img)\n",
    "        cv2.imshow(\"thresh\", processed_img)\n",
    "        keypress = cv2.waitKey(1)\n",
    "        if not keypress==-1:\n",
    "            print(\"Key number: \",keypress)\n",
    "        if keypress%256 == 27:\n",
    "            # 'ESC' pressed\n",
    "            print(\"Escape hit, closing...\")\n",
    "            a=10\n",
    "            for s in sent:\n",
    "                i=5\n",
    "                a += i\n",
    "                cv2.putText(img, s, (30, a), cv2.FONT_HERSHEY_TRIPLEX, 2, (127, 255, 255))\n",
    "                speak.Speak(s)\n",
    "                \n",
    "            break\n",
    "        frames +=1\n",
    "        \n",
    "loaded_model = load_new_model()\n",
    "try:\n",
    "    start_camera(loaded_model)\n",
    "except Exception as e:\n",
    "    print(\"Something Happened :\",e)\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
