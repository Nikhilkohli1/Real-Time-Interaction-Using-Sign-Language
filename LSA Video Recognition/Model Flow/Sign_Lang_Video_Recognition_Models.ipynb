{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "continuation",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "lk9WeuTh3hO-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "0367e384-6677-4ddb-8cb2-d7d111c7e47f"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UZKol_rk3nql",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "19a978aa-2768-45de-b96d-ee25d4979761"
      },
      "cell_type": "code",
      "source": [
        "cd /content/drive/My Drive/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0Tw2sz5z36cn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "e18dd987-1fab-464e-8264-808e18864cd3"
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Alayam.wav.mp4\n",
            " American.Truck.Simulator.v1.31.1s.rar\n",
            "'Assignment 3.zip'\n",
            "\u001b[0m\u001b[01;34m'Colab Notebooks'\u001b[0m/\n",
            " \u001b[01;34mdance\u001b[0m/\n",
            " densenet121_weights_tf.h5\n",
            " DenseNet-Keras-master.zip\n",
            " DS_Team.gsheet\n",
            " events.out.tfevents.1556069833.fa6951a9390c\n",
            " events.out.tfevents.1556069942.fa6951a9390c\n",
            "\u001b[01;34m'Fine Tune'\u001b[0m/\n",
            " \u001b[01;34mfive-video-classification-methods-master\u001b[0m/\n",
            " glove.6B.100d.txt.zip\n",
            " \u001b[01;34mImageNet\u001b[0m/\n",
            " IMG_1631.JPG\n",
            " loan.csv\n",
            " lstm-features.010-0.108.h5\n",
            " sequences-20190423T192913Z-001.zip\n",
            " Team_15.gsheet\n",
            " VIDEO-2018-12-22-05-46-06.mp4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nbylsJQC38QX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5f0a080a-e51f-49c4-818d-525cfe450aa6"
      },
      "cell_type": "code",
      "source": [
        "cd five-video-classification-methods-master"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/five-video-classification-methods-master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8Y87--zs3-7x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22d501d3-3f1d-4af7-d9eb-5260984017bf"
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "from keras.layers.convolutional import (Conv2D, MaxPooling3D, Conv3D,\n",
        "    MaxPooling2D)\n",
        "from collections import deque\n",
        "import sys"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "88ahP3mX4EES",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ResearchModels():\n",
        "    \n",
        "    def __init__(self, nb_classes, model, seq_length,\n",
        "                     saved_model=None, features_length=2048):\n",
        "\n",
        "        self.seq_length = seq_length\n",
        "        self.load_model = load_model\n",
        "        self.saved_model = saved_model\n",
        "        self.nb_classes = nb_classes\n",
        "        self.feature_queue = deque()\n",
        "\n",
        "        metrics = ['accuracy']\n",
        "        if self.nb_classes >= 10:\n",
        "            metrics.append('top_k_categorical_accuracy')\n",
        "\n",
        "        if self.saved_model is not None:\n",
        "            print(\"Loading model %s\" % self.saved_model)\n",
        "            self.model = load_model(self.saved_model)\n",
        "        elif model == 'lstm':\n",
        "            print(\"Loading LSTM model.\")\n",
        "            self.input_shape = (seq_length, features_length)\n",
        "            self.model = self.lstm()\n",
        "        elif model == 'lrcn':\n",
        "            print(\"Loading CNN-LSTM model.\")\n",
        "            self.input_shape = (seq_length, 80, 80, 3)\n",
        "            self.model = self.lrcn()\n",
        "        elif model == 'mlp':\n",
        "            print(\"Loading simple MLP.\")\n",
        "            self.input_shape = (seq_length, features_length)\n",
        "            self.model = self.mlp()\n",
        "        elif model == 'conv_3d':\n",
        "            print(\"Loading Conv3D\")\n",
        "            self.input_shape = (seq_length, 80, 80, 3)\n",
        "            self.model = self.conv_3d()\n",
        "        elif model == 'c3d':\n",
        "            print(\"Loading C3D\")\n",
        "            self.input_shape = (seq_length, 80, 80, 3)\n",
        "            self.model = self.c3d()\n",
        "        else:\n",
        "            print(\"Unknown network.\")\n",
        "            sys.exit()\n",
        "\n",
        "        # Now compile the network.\n",
        "        optimizer = Adam(lr=1e-5, decay=1e-6)\n",
        "        self.model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n",
        "                           metrics=metrics)\n",
        "\n",
        "        print(self.model.summary())\n",
        "        \n",
        "    def lstm(self):\n",
        "        \n",
        "            \n",
        "        \"\"\"Build a simple LSTM network. We pass the extracted features from\n",
        "        our CNN to this model predomenently.\"\"\"\n",
        "        # Model.\n",
        "        model = Sequential()\n",
        "        model.add(LSTM(2048, return_sequences=False,\n",
        "                       input_shape=self.input_shape,\n",
        "                       dropout=0.2))\n",
        "        model.add(Dense(512, activation='relu'))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(Dense(self.nb_classes, activation='softmax'))\n",
        "\n",
        "        return model\n",
        "      \n",
        "    def lrcn(self):\n",
        "        \"\"\"Build a CNN into RNN.\n",
        "        Starting version from:\n",
        "            https://github.com/udacity/self-driving-car/blob/master/\n",
        "                steering-models/community-models/chauffeur/models.py\n",
        "\n",
        "        Heavily influenced by VGG-16:\n",
        "            https://arxiv.org/abs/1409.1556\n",
        "\n",
        "        Also known as an LRCN:\n",
        "            https://arxiv.org/pdf/1411.4389.pdf\n",
        "        \"\"\"\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(TimeDistributed(Conv2D(32, (7, 7), strides=(2, 2),\n",
        "            activation='relu', padding='same'), input_shape=self.input_shape))\n",
        "        model.add(TimeDistributed(Conv2D(32, (3,3),\n",
        "            kernel_initializer=\"he_normal\", activation='relu')))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "\n",
        "        model.add(TimeDistributed(Conv2D(64, (3,3),\n",
        "            padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(Conv2D(64, (3,3),\n",
        "            padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "\n",
        "        model.add(TimeDistributed(Conv2D(128, (3,3),\n",
        "            padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(Conv2D(128, (3,3),\n",
        "            padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "\n",
        "        model.add(TimeDistributed(Conv2D(256, (3,3),\n",
        "            padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(Conv2D(256, (3,3),\n",
        "            padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "        \n",
        "        model.add(TimeDistributed(Conv2D(512, (3,3),\n",
        "            padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(Conv2D(512, (3,3),\n",
        "            padding='same', activation='relu')))\n",
        "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
        "\n",
        "        model.add(TimeDistributed(Flatten()))\n",
        "\n",
        "        model.add(Dropout(0.5))\n",
        "        model.add(LSTM(256, return_sequences=False, dropout=0.5))\n",
        "        model.add(Dense(self.nb_classes, activation='softmax'))\n",
        "\n",
        "        return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AglSJ8gu4MqE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger\n",
        "from data import DataSet\n",
        "import time\n",
        "import os.path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y8owcYJT4PQP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(data_type, seq_length, model, saved_model=None,\n",
        "          class_limit=None, image_shape=None,\n",
        "          load_to_memory=False, batch_size=32, nb_epoch=100):\n",
        "    # Helper: Save the model.\n",
        "    checkpointer = ModelCheckpoint(\n",
        "        filepath=os.path.join('data', 'checkpoints', model + '-' + data_type + \\\n",
        "            '.{epoch:03d}-{val_loss:.3f}.hdf5'),\n",
        "        verbose=1,\n",
        "        save_best_only=True)\n",
        "\n",
        "    # Helper: TensorBoard\n",
        "    tb = TensorBoard(log_dir=os.path.join('data', 'logs', model))\n",
        "\n",
        "    # Helper: Stop when we stop learning.\n",
        "    early_stopper = EarlyStopping(patience=5)\n",
        "\n",
        "    # Helper: Save results.\n",
        "    timestamp = time.time()\n",
        "    csv_logger = CSVLogger(os.path.join('data', 'logs', model + '-' + 'training-' + \\\n",
        "        str(timestamp) + '.log'))\n",
        "\n",
        "    # Get the data and process it.\n",
        "    if image_shape is None:\n",
        "        data = DataSet(\n",
        "            seq_length=seq_length,\n",
        "            class_limit=class_limit\n",
        "        )\n",
        "    else:\n",
        "        data = DataSet(\n",
        "            seq_length=seq_length,\n",
        "            class_limit=class_limit,\n",
        "            image_shape=image_shape\n",
        "        )\n",
        "\n",
        "    # Get samples per epoch.\n",
        "    # Multiply by 0.7 to attempt to guess how much of data.data is the train set.\n",
        "    steps_per_epoch = (len(data.data) * 0.7) // batch_size\n",
        "\n",
        "    if load_to_memory:\n",
        "        # Get data.\n",
        "        X, y = data.get_all_sequences_in_memory('train', data_type)\n",
        "        X_test, y_test = data.get_all_sequences_in_memory('test', data_type)\n",
        "    else:\n",
        "        # Get generators.\n",
        "        generator = data.frame_generator(batch_size, 'train', data_type)\n",
        "        val_generator = data.frame_generator(batch_size, 'test', data_type)\n",
        "\n",
        "    # Get the model.\n",
        "    rm = ResearchModels(len(data.classes), model, seq_length, saved_model)\n",
        "\n",
        "    # Fit!\n",
        "    if load_to_memory:\n",
        "        # Use standard fit.\n",
        "        rm.model.fit(\n",
        "            X,\n",
        "            y,\n",
        "            batch_size=batch_size,\n",
        "            validation_data=(X_test, y_test),\n",
        "            verbose=1,\n",
        "            callbacks=[tb, early_stopper, csv_logger],\n",
        "            epochs=nb_epoch)\n",
        "    else:\n",
        "        # Use fit generator.\n",
        "        rm.model.fit_generator(\n",
        "            generator=generator,\n",
        "            steps_per_epoch=steps_per_epoch,\n",
        "            epochs=nb_epoch,\n",
        "            verbose=1,\n",
        "            callbacks=[tb, early_stopper, csv_logger, checkpointer],\n",
        "            validation_data=val_generator,\n",
        "            validation_steps=40,\n",
        "            workers=4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c-GC16ms4hA0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"These are the main training settings. Set each before running\n",
        "    this file.\"\"\"\n",
        "    # model can be one of lstm, lrcn, mlp, conv_3d, c3d\n",
        "    model = 'lstm'\n",
        "    saved_model = None  # None or weights file\n",
        "    class_limit = None  # int, can be 1-101 or None\n",
        "    seq_length = 40\n",
        "    load_to_memory = False  # pre-load the sequences into memory\n",
        "    batch_size = 1\n",
        "    nb_epoch = 10\n",
        "\n",
        "    # Chose images or features and image shape based on network.\n",
        "    if model in ['conv_3d', 'c3d', 'lrcn']:\n",
        "        data_type = 'images'\n",
        "        image_shape = (80, 80, 3)\n",
        "    elif model in ['lstm', 'mlp']:\n",
        "        data_type = 'features'\n",
        "        image_shape = None\n",
        "    else:\n",
        "        raise ValueError(\"Invalid model. See train.py for options.\")\n",
        "        \n",
        "    train(data_type, seq_length, model, saved_model=saved_model,\n",
        "          class_limit=class_limit, image_shape=image_shape,\n",
        "          load_to_memory=load_to_memory, batch_size=batch_size, nb_epoch=nb_epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UEbQ-VSv4lc6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1040
        },
        "outputId": "20a76e90-3d3f-4825-a2a6-856b698c1a3e"
      },
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading LSTM model.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_3 (LSTM)                (None, 2048)              33562624  \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 24)                12312     \n",
            "=================================================================\n",
            "Total params: 34,624,024\n",
            "Trainable params: 34,624,024\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "Creating train generator with 942 samples.Creating test generator with 235 samples.\n",
            "\n",
            "823/823 [==============================] - 244s 296ms/step - loss: 2.5592 - acc: 0.3232 - top_k_categorical_accuracy: 0.6367 - val_loss: 1.5971 - val_acc: 0.6250 - val_top_k_categorical_accuracy: 0.9000\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.59710, saving model to data/checkpoints/lstm-features.001-1.597.hdf5\n",
            "Epoch 2/10\n",
            "823/823 [==============================] - 241s 292ms/step - loss: 1.0789 - acc: 0.7181 - top_k_categorical_accuracy: 0.9587 - val_loss: 1.0783 - val_acc: 0.6500 - val_top_k_categorical_accuracy: 0.9750\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.59710 to 1.07835, saving model to data/checkpoints/lstm-features.002-1.078.hdf5\n",
            "Epoch 3/10\n",
            "823/823 [==============================] - 242s 294ms/step - loss: 0.4914 - acc: 0.8809 - top_k_categorical_accuracy: 0.9976 - val_loss: 0.2106 - val_acc: 0.9500 - val_top_k_categorical_accuracy: 1.0000\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.07835 to 0.21056, saving model to data/checkpoints/lstm-features.003-0.211.hdf5\n",
            "Epoch 4/10\n",
            "823/823 [==============================] - 242s 294ms/step - loss: 0.2915 - acc: 0.9332 - top_k_categorical_accuracy: 0.9964 - val_loss: 0.1827 - val_acc: 0.9250 - val_top_k_categorical_accuracy: 1.0000\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.21056 to 0.18270, saving model to data/checkpoints/lstm-features.004-0.183.hdf5\n",
            "Epoch 5/10\n",
            "823/823 [==============================] - 242s 294ms/step - loss: 0.2288 - acc: 0.9514 - top_k_categorical_accuracy: 0.9951 - val_loss: 0.1325 - val_acc: 0.9750 - val_top_k_categorical_accuracy: 1.0000\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.18270 to 0.13246, saving model to data/checkpoints/lstm-features.005-0.132.hdf5\n",
            "Epoch 6/10\n",
            "823/823 [==============================] - 241s 292ms/step - loss: 0.1799 - acc: 0.9526 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0717 - val_acc: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.13246 to 0.07174, saving model to data/checkpoints/lstm-features.006-0.072.hdf5\n",
            "Epoch 7/10\n",
            "823/823 [==============================] - 241s 293ms/step - loss: 0.1165 - acc: 0.9708 - top_k_categorical_accuracy: 0.9988 - val_loss: 0.1278 - val_acc: 0.9750 - val_top_k_categorical_accuracy: 1.0000\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.07174\n",
            "Epoch 8/10\n",
            "823/823 [==============================] - 242s 294ms/step - loss: 0.1162 - acc: 0.9672 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.0681 - val_acc: 1.0000 - val_top_k_categorical_accuracy: 1.0000\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.07174 to 0.06805, saving model to data/checkpoints/lstm-features.008-0.068.hdf5\n",
            "Epoch 9/10\n",
            "823/823 [==============================] - 243s 295ms/step - loss: 0.0959 - acc: 0.9781 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.6028 - val_acc: 0.8750 - val_top_k_categorical_accuracy: 1.0000\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.06805\n",
            "Epoch 10/10\n",
            "823/823 [==============================] - 242s 294ms/step - loss: 0.0679 - acc: 0.9878 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.4603 - val_acc: 0.9000 - val_top_k_categorical_accuracy: 1.0000\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.06805\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y89Wyj4l4mtH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4700b90-38ad-4bf5-c2be-bdd2dbd7338b"
      },
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/My Drive/five-video-classification-methods-master'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "17-yaC_J--Eb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}