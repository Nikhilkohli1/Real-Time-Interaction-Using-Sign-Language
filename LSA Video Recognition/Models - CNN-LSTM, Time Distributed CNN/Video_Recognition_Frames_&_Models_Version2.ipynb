{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extractor\n",
    "\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "import numpy as np\n",
    "\n",
    "class Extractor():\n",
    "    def __init__(self, weights=None):\n",
    "        \"\"\"Either load pretrained from imagenet, or load our saved\n",
    "        weights from our own training.\"\"\"\n",
    "\n",
    "        self.weights = weights  # so we can check elsewhere which model\n",
    "\n",
    "        if weights is None:\n",
    "            # Get model with pretrained weights.\n",
    "            base_model = InceptionV3(\n",
    "                weights='imagenet',\n",
    "                include_top=True\n",
    "            )\n",
    "\n",
    "            # We'll extract features at the final pool layer.\n",
    "            self.model = Model(\n",
    "                inputs=base_model.input,\n",
    "                outputs=base_model.get_layer('avg_pool').output\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            # Load the model first.\n",
    "            self.model = load_model(weights)\n",
    "\n",
    "            # Then remove the top so we get features not predictions.\n",
    "            # From: https://github.com/fchollet/keras/issues/2371\n",
    "            self.model.layers.pop()\n",
    "            self.model.layers.pop()  # two pops to get to pool layer\n",
    "            self.model.outputs = [self.model.layers[-1].output]\n",
    "            self.model.output_layers = [self.model.layers[-1]]\n",
    "            self.model.layers[-1].outbound_nodes = []\n",
    "\n",
    "    def extract(self, image_path):\n",
    "        img = image.load_img(image_path, target_size=(299, 299))\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "\n",
    "        # Get the prediction.\n",
    "        features = self.model.predict(x)\n",
    "\n",
    "        if self.weights is None:\n",
    "            # For imagenet/default network:\n",
    "            features = features[0]\n",
    "        else:\n",
    "            # For loaded network:\n",
    "            features = features[0]\n",
    "\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Class for managing our data.\n",
    "\"\"\"\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import os.path\n",
    "import sys\n",
    "import operator\n",
    "import threading\n",
    "#from processor import process_image\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "class threadsafe_iterator:\n",
    "    def __init__(self, iterator):\n",
    "        self.iterator = iterator\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        with self.lock:\n",
    "            return next(self.iterator)\n",
    "\n",
    "def threadsafe_generator(func):\n",
    "    \"\"\"Decorator\"\"\"\n",
    "    def gen(*a, **kw):\n",
    "        return threadsafe_iterator(func(*a, **kw))\n",
    "    return gen\n",
    "\n",
    "class DataSet():\n",
    "\n",
    "    def __init__(self, seq_length=20, class_limit=None, image_shape=(224, 224, 3)):\n",
    "        \"\"\"Constructor.\n",
    "        seq_length = (int) the number of frames to consider\n",
    "        class_limit = (int) number of classes to limit the data to.\n",
    "            None = no limit.\n",
    "        \"\"\"\n",
    "        self.seq_length = seq_length\n",
    "        self.class_limit = class_limit\n",
    "        self.sequence_path = os.path.join('data', 'sequences')\n",
    "        self.max_frames = 300  # max number of frames a video can have for us to use it\n",
    "\n",
    "        # Get the data.\n",
    "        self.data = self.get_data()\n",
    "\n",
    "        # Get the classes.\n",
    "        self.classes = self.get_classes()\n",
    "\n",
    "        # Now do some minor data cleaning.\n",
    "        self.data = self.clean_data()\n",
    "\n",
    "        self.image_shape = image_shape\n",
    "\n",
    "    @staticmethod\n",
    "    def get_data():\n",
    "        \"\"\"Load our data from file.\"\"\"\n",
    "        with open(os.path.join('data', 'data_file.csv'), 'r') as fin:\n",
    "            reader = csv.reader(fin)\n",
    "            data = list(reader)\n",
    "\n",
    "        return data\n",
    "\n",
    "    def clean_data(self):\n",
    "        \"\"\"Limit samples to greater than the sequence length and fewer\n",
    "        than N frames. Also limit it to classes we want to use.\"\"\"\n",
    "        data_clean = []\n",
    "        for item in self.data:\n",
    "            if int(item[3]) >= self.seq_length and int(item[3]) <= self.max_frames \\\n",
    "                    and item[1] in self.classes:\n",
    "                data_clean.append(item)\n",
    "\n",
    "        return data_clean\n",
    "\n",
    "    def get_classes(self):\n",
    "        \"\"\"Extract the classes from our data. If we want to limit them,\n",
    "        only return the classes we need.\"\"\"\n",
    "        classes = []\n",
    "        for item in self.data:\n",
    "            if item[1] not in classes:\n",
    "                classes.append(item[1])\n",
    "\n",
    "        # Sort them.\n",
    "        classes = sorted(classes)\n",
    "\n",
    "        # Return.\n",
    "        if self.class_limit is not None:\n",
    "            return classes[:self.class_limit]\n",
    "        else:\n",
    "            return classes\n",
    "\n",
    "    def get_class_one_hot(self, class_str):\n",
    "        \"\"\"Given a class as a string, return its number in the classes\n",
    "        list. This lets us encode and one-hot it for training.\"\"\"\n",
    "        # Encode it first.\n",
    "        label_encoded = self.classes.index(class_str)\n",
    "\n",
    "        # Now one-hot it.\n",
    "        label_hot = to_categorical(label_encoded, len(self.classes))\n",
    "\n",
    "        assert len(label_hot) == len(self.classes)\n",
    "\n",
    "        return label_hot\n",
    "\n",
    "    def split_train_test(self):\n",
    "        \"\"\"Split the data into train and test groups.\"\"\"\n",
    "        train = []\n",
    "        test = []\n",
    "        for item in self.data:\n",
    "            if item[0] == 'train':\n",
    "                train.append(item)\n",
    "            else:\n",
    "                test.append(item)\n",
    "        return train, test\n",
    "\n",
    "    def get_all_sequences_in_memory(self, train_test, data_type):\n",
    "        \"\"\"\n",
    "        This is a mirror of our generator, but attempts to load everything into\n",
    "        memory so we can train way faster.\n",
    "        \"\"\"\n",
    "        # Get the right dataset.\n",
    "        train, test = self.split_train_test()\n",
    "        data = train if train_test == 'train' else test\n",
    "\n",
    "        print(\"Loading %d samples into memory for %sing.\" % (len(data), train_test))\n",
    "\n",
    "        X, y = [], []\n",
    "        for row in data:\n",
    "\n",
    "            if data_type == 'images':\n",
    "                frames = self.get_frames_for_sample(row)\n",
    "                frames = self.rescale_list(frames, self.seq_length)\n",
    "\n",
    "                # Build the image sequence\n",
    "                sequence = self.build_image_sequence(frames)\n",
    "\n",
    "            else:\n",
    "                sequence = self.get_extracted_sequence(data_type, row)\n",
    "\n",
    "                if sequence is None:\n",
    "                    print(\"Can't find sequence. Did you generate them?\")\n",
    "                    raise\n",
    "\n",
    "            X.append(sequence)\n",
    "            y.append(self.get_class_one_hot(row[1]))\n",
    "\n",
    "        return np.array(X), np.array(y)\n",
    "\n",
    "    @threadsafe_generator\n",
    "    def frame_generator(self, batch_size, train_test, data_type):\n",
    "        \"\"\"Return a generator that we can use to train on. There are\n",
    "        a couple different things we can return:\n",
    "        data_type: 'features', 'images'\n",
    "        \"\"\"\n",
    "        # Get the right dataset for the generator.\n",
    "        train, test = self.split_train_test()\n",
    "        data = train if train_test == 'train' else test\n",
    "\n",
    "        print(\"Creating %s generator with %d samples.\" % (train_test, len(data)))\n",
    "\n",
    "        while 1:\n",
    "            X, y = [], []\n",
    "\n",
    "            # Generate batch_size samples.\n",
    "            for _ in range(batch_size):\n",
    "                # Reset to be safe.\n",
    "                sequence = None\n",
    "\n",
    "                # Get a random sample.\n",
    "                sample = random.choice(data)\n",
    "\n",
    "                # Check to see if we've already saved this sequence.\n",
    "                if data_type is \"images\":\n",
    "                    # Get and resample frames.\n",
    "                    frames = self.get_frames_for_sample(sample)\n",
    "\n",
    "                    # Build the image sequence\n",
    "                    sequence = self.build_image_sequence(frames)\n",
    "                else:\n",
    "                    # Get the sequence from disk.\n",
    "                    sequence = self.get_extracted_sequence(data_type, sample)\n",
    "\n",
    "                    if sequence is None:\n",
    "                        raise ValueError(\"Can't find sequence. Did you generate them?\")\n",
    "\n",
    "                X.append(sequence)\n",
    "                y.append(self.get_class_one_hot(sample[1]))\n",
    "\n",
    "            yield np.array(X), np.array(y)\n",
    "\n",
    "    def build_image_sequence(self, frames):\n",
    "        \"\"\"Given a set of frames (filenames), build our sequence.\"\"\"\n",
    "        return [process_image(x, self.image_shape) for x in frames]\n",
    "\n",
    "    def get_extracted_sequence(self, data_type, sample):\n",
    "        \"\"\"Get the saved extracted features.\"\"\"\n",
    "        filename = sample[2]\n",
    "        path = os.path.join(self.sequence_path, filename + '-' + str(self.seq_length) + \\\n",
    "            '-' + data_type + '.npy')\n",
    "        if os.path.isfile(path):\n",
    "            return np.load(path)\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_frames_by_filename(self, filename, data_type):\n",
    "        \"\"\"Given a filename for one of our samples, return the data\n",
    "        the model needs to make predictions.\"\"\"\n",
    "        # First, find the sample row.\n",
    "        sample = None\n",
    "        for row in self.data:\n",
    "            if row[2] == filename:\n",
    "                sample = row\n",
    "                break\n",
    "        if sample is None:\n",
    "            raise ValueError(\"Couldn't find sample: %s\" % filename)\n",
    "\n",
    "        if data_type == \"images\":\n",
    "            # Get and resample frames.\n",
    "            frames = self.get_frames_for_sample(sample)\n",
    "            frames = self.rescale_list(frames, self.seq_length)\n",
    "            # Build the image sequence\n",
    "            sequence = self.build_image_sequence(frames)\n",
    "        else:\n",
    "            # Get the sequence from disk.\n",
    "            sequence = self.get_extracted_sequence(data_type, sample)\n",
    "\n",
    "            if sequence is None:\n",
    "                raise ValueError(\"Can't find sequence. Did you generate them?\")\n",
    "\n",
    "        return sequence\n",
    "\n",
    "    @staticmethod\n",
    "    def get_frames_for_sample(sample):\n",
    "        \"\"\"Given a sample row from the data file, get all the corresponding frame\n",
    "        filenames.\"\"\"\n",
    "        path = os.path.join('data', sample[0], sample[1])\n",
    "        filename = sample[2]\n",
    "        images = sorted(glob.glob(os.path.join(path, filename + '*jpg')))\n",
    "        return images\n",
    "\n",
    "    @staticmethod\n",
    "    def get_filename_from_image(filename):\n",
    "        parts = filename.split(os.path.sep)\n",
    "        return parts[-1].replace('.jpg', '')\n",
    "\n",
    "    @staticmethod\n",
    "    def rescale_list(input_list, size):\n",
    "        \"\"\"Given a list and a size, return a rescaled/samples list. For example,\n",
    "        if we want a list of size 5 and we have a list of size 25, return a new\n",
    "        list of size five which is every 5th element of the origina list.\"\"\"\n",
    "        assert len(input_list) >= size\n",
    "\n",
    "        # Get the number to skip between iterations.\n",
    "        skip = len(input_list) // size\n",
    "\n",
    "        # Build our new output.\n",
    "        output = [input_list[i] for i in range(0, len(input_list), skip)]\n",
    "\n",
    "        # Cut off the last one if needed.\n",
    "        return output[:size]\n",
    "\n",
    "    def print_class_from_prediction(self, predictions, nb_to_return=5):\n",
    "        \"\"\"Given a prediction, print the top classes.\"\"\"\n",
    "        # Get the prediction for each label.\n",
    "        label_predictions = {}\n",
    "        for i, label in enumerate(self.classes):\n",
    "            label_predictions[label] = predictions[i]\n",
    "\n",
    "        # Now sort them.\n",
    "        sorted_lps = sorted(\n",
    "            label_predictions.items(),\n",
    "            key=operator.itemgetter(1),\n",
    "            reverse=True\n",
    "        )\n",
    "\n",
    "        # And return the top N.\n",
    "        for i, class_prediction in enumerate(sorted_lps):\n",
    "            if i > nb_to_return - 1 or class_prediction[1] == 0.0:\n",
    "                break\n",
    "            print(\"%s: %.2f\" % (class_prediction[0], class_prediction[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Extract Features \n",
    "\n",
    "import numpy as np\n",
    "import os.path\n",
    "#from data import DataSet\n",
    "#from extractor import Extractor\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set defaults.\n",
    "seq_length = 20\n",
    "class_limit = None  # Number of classes to extract. Can be 1-101 or None for all.\n",
    "\n",
    "# Get the dataset.\n",
    "data = DataSet(seq_length=seq_length, class_limit=class_limit)\n",
    "\n",
    "# get the model.\n",
    "model = Extractor()\n",
    "\n",
    "# Loop through data.\n",
    "pbar = tqdm(total=len(data.data))\n",
    "for video in data.data:\n",
    "\n",
    "    # Get the path to the sequence for this video.\n",
    "    path = os.path.join('data', 'sequences', video[2] + '-' + str(seq_length) + \\\n",
    "        '-features')  # numpy will auto-append .npy\n",
    "\n",
    "    # Check if we already have it.\n",
    "    if os.path.isfile(path + '.npy'):\n",
    "        #pbar.update(1)\n",
    "        continue\n",
    "\n",
    "    # Get the frames for this video.\n",
    "    frames = data.get_frames_for_sample(video)\n",
    "\n",
    "    # Now downsample to just the ones we need.\n",
    "    #frames = data.rescale_list(frames, seq_length)\n",
    "\n",
    "    # Now loop through and extract features to build the sequence.\n",
    "    sequence = []\n",
    "    for image in frames:\n",
    "        features = model.extract(image)\n",
    "        sequence.append(features)\n",
    "\n",
    "    # Save the sequence.\n",
    "    np.save(path, sequence)\n",
    "\n",
    "    #pbar.update(1)\n",
    "\n",
    "#pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.convolutional import (Conv2D, MaxPooling3D, Conv3D,\n",
    "    MaxPooling2D)\n",
    "from collections import deque\n",
    "import sys\n",
    "\n",
    "class ResearchModels():\n",
    "    def __init__(self, nb_classes, model, seq_length,\n",
    "                 saved_model=None, features_length=2048):\n",
    "        \"\"\"\n",
    "        `model` = one of:\n",
    "            lstm\n",
    "            lrcn\n",
    "            mlp\n",
    "            conv_3d\n",
    "            c3d\n",
    "        `nb_classes` = the number of classes to predict\n",
    "        `seq_length` = the length of our video sequences\n",
    "        `saved_model` = the path to a saved Keras model to load\n",
    "        \"\"\"\n",
    "\n",
    "        # Set defaults.\n",
    "        self.seq_length = seq_length\n",
    "        self.load_model = load_model\n",
    "        self.saved_model = saved_model\n",
    "        self.nb_classes = nb_classes\n",
    "        self.feature_queue = deque()\n",
    "\n",
    "        # Set the metrics. Only use top k if there's a need.\n",
    "        metrics = ['accuracy']\n",
    "        if self.nb_classes >= 10:\n",
    "            metrics.append('top_k_categorical_accuracy')\n",
    "\n",
    "        # Get the appropriate model.\n",
    "        if self.saved_model is not None:\n",
    "            print(\"Loading model %s\" % self.saved_model)\n",
    "            self.model = load_model(self.saved_model)\n",
    "        elif model == 'lstm':\n",
    "            print(\"Loading LSTM model.\")\n",
    "            self.input_shape = (seq_length, features_length)\n",
    "            self.model = self.lstm()\n",
    "        elif model == 'lrcn':\n",
    "            print(\"Loading CNN-LSTM model.\")\n",
    "            self.input_shape = (seq_length, 80, 80, 3)\n",
    "            self.model = self.lrcn()\n",
    "        elif model == 'mlp':\n",
    "            print(\"Loading simple MLP.\")\n",
    "            self.input_shape = (seq_length, features_length)\n",
    "            self.model = self.mlp()\n",
    "        elif model == 'conv_3d':\n",
    "            print(\"Loading Conv3D\")\n",
    "            self.input_shape = (seq_length, 80, 80, 3)\n",
    "            self.model = self.conv_3d()\n",
    "        elif model == 'c3d':\n",
    "            print(\"Loading C3D\")\n",
    "            self.input_shape = (seq_length, 80, 80, 3)\n",
    "            self.model = self.c3d()\n",
    "        else:\n",
    "            print(\"Unknown network.\")\n",
    "            sys.exit()\n",
    "\n",
    "        # Now compile the network.\n",
    "        optimizer = Adam(lr=1e-5, decay=1e-6)\n",
    "        self.model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n",
    "                           metrics=metrics)\n",
    "\n",
    "        print(self.model.summary())\n",
    "\n",
    "    \n",
    "    def lrcn(self):\n",
    "        \"\"\"Build a CNN into RNN.\n",
    "        Starting version from:\n",
    "            https://github.com/udacity/self-driving-car/blob/master/\n",
    "                steering-models/community-models/chauffeur/models.py\n",
    "        Heavily influenced by VGG-16:\n",
    "            https://arxiv.org/abs/1409.1556\n",
    "        Also known as an LRCN:\n",
    "            https://arxiv.org/pdf/1411.4389.pdf\n",
    "        \"\"\"\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(32, (7, 7), strides=(2, 2),\n",
    "            activation='relu', padding='same'), input_shape=self.input_shape))\n",
    "        model.add(TimeDistributed(Conv2D(32, (3,3),\n",
    "            kernel_initializer=\"he_normal\", activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(64, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(64, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(128, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(128, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Conv2D(256, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(256, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "        \n",
    "        model.add(TimeDistributed(Conv2D(512, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(Conv2D(512, (3,3),\n",
    "            padding='same', activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(LSTM(256, return_sequences=False, dropout=0.5))\n",
    "        model.add(Dense(self.nb_classes, activation='softmax'))\n",
    "\n",
    "        return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train our RNN on extracted features or images.\n",
    "\"\"\"\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping#, CSVLogger\n",
    "#from models import ResearchModels\n",
    "#from data import DataSet\n",
    "import time\n",
    "import os.path\n",
    "\n",
    "def train(data_type, seq_length, model, saved_model=None,\n",
    "          class_limit=None, image_shape=None,\n",
    "          load_to_memory=False, batch_size=1, nb_epoch=10):\n",
    "    # Helper: Save the model.\n",
    "#     checkpointer = ModelCheckpoint(\n",
    "#         filepath=os.path.join('data', 'checkpoints', model + '-' + data_type + \\\n",
    "#             '.{epoch:03d}-{val_loss:.3f}.hdf5'),\n",
    "#         verbose=1,\n",
    "#         save_best_only=True)\n",
    "\n",
    "    # Helper: TensorBoard\n",
    "    #tb = TensorBoard(log_dir=os.path.join('data', 'logs', model))\n",
    "\n",
    "    # Helper: Stop when we stop learning.\n",
    "    early_stopper = EarlyStopping(patience=5)\n",
    "\n",
    "    # Helper: Save results.\n",
    "    #timestamp = time.time()\n",
    "    #csv_logger = CSVLogger(os.path.join('data', 'logs', model + '-' + 'training-' + \\\n",
    "     #   str(timestamp) + '.log'))\n",
    "\n",
    "    # Get the data and process it.\n",
    "    if image_shape is None:\n",
    "        data = DataSet(\n",
    "            seq_length=seq_length,\n",
    "            class_limit=class_limit\n",
    "        )\n",
    "    else:\n",
    "        data = DataSet(\n",
    "            seq_length=seq_length,\n",
    "            class_limit=class_limit,\n",
    "            image_shape=image_shape\n",
    "        )\n",
    "\n",
    "    # Get samples per epoch.\n",
    "    # Multiply by 0.7 to attempt to guess how much of data.data is the train set.\n",
    "    steps_per_epoch = (len(data.data) * 0.7) // batch_size\n",
    "\n",
    "    if load_to_memory:\n",
    "        # Get data.\n",
    "        X, y = data.get_all_sequences_in_memory('train', data_type)\n",
    "        X_test, y_test = data.get_all_sequences_in_memory('test', data_type)\n",
    "    else:\n",
    "        # Get generators.\n",
    "        generator = data.frame_generator(batch_size, 'train', data_type)\n",
    "        val_generator = data.frame_generator(batch_size, 'test', data_type)\n",
    "\n",
    "    # Get the model.\n",
    "    rm = ResearchModels(len(data.classes), model, seq_length, saved_model)\n",
    "\n",
    "    # Fit!\n",
    "    if load_to_memory:\n",
    "        # Use standard fit.\n",
    "        rm.model.fit(\n",
    "            X,\n",
    "            y,\n",
    "            batch_size=batch_size,\n",
    "            validation_data=(X_test, y_test),\n",
    "            verbose=1,\n",
    "            #callbacks=[tb, early_stopper, csv_logger],\n",
    "            epochs=nb_epoch)\n",
    "    else:\n",
    "        # Use fit generator.\n",
    "        rm.model.fit_generator(\n",
    "            generator=generator,\n",
    "            steps_per_epoch=steps_per_epoch,\n",
    "            epochs=nb_epoch,\n",
    "            verbose=1,\n",
    "            #callbacks=[ early_stopper, csv_logger, checkpointer],\n",
    "            validation_data=val_generator,\n",
    "            validation_steps=40,\n",
    "            workers=4)\n",
    "\n",
    "def main():\n",
    "    \"\"\"These are the main training settings. Set each before running\n",
    "    this file.\"\"\"\n",
    "    # model can be one of lstm, lrcn, mlp, conv_3d, c3d\n",
    "    model = 'lrcn'\n",
    "    saved_model = None  # None or weights file\n",
    "    class_limit = None  # int, can be 1-101 or None\n",
    "    seq_length = 20\n",
    "    load_to_memory = False  # pre-load the sequences into memory\n",
    "    batch_size = 1\n",
    "    nb_epoch = 10\n",
    "\n",
    "    # Chose images or features and image shape based on network.\n",
    "    if model in ['conv_3d', 'c3d', 'lrcn']:\n",
    "        data_type = 'images'\n",
    "        image_shape = (80, 80, 3)\n",
    "    elif model in ['lstm', 'mlp']:\n",
    "        data_type = 'features'\n",
    "        image_shape = None\n",
    "    else:\n",
    "        raise ValueError(\"Invalid model. See train.py for options.\")\n",
    "\n",
    "    train(data_type, seq_length, model, saved_model=saved_model,\n",
    "          class_limit=class_limit, image_shape=image_shape,\n",
    "          load_to_memory=load_to_memory, batch_size=batch_size, nb_epoch=nb_epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CNN-LSTM model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_177 (TimeDi (None, 20, 40, 40, 32)    4736      \n",
      "_________________________________________________________________\n",
      "time_distributed_178 (TimeDi (None, 20, 38, 38, 32)    9248      \n",
      "_________________________________________________________________\n",
      "time_distributed_179 (TimeDi (None, 20, 19, 19, 32)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_180 (TimeDi (None, 20, 19, 19, 64)    18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_181 (TimeDi (None, 20, 19, 19, 64)    36928     \n",
      "_________________________________________________________________\n",
      "time_distributed_182 (TimeDi (None, 20, 9, 9, 64)      0         \n",
      "_________________________________________________________________\n",
      "time_distributed_183 (TimeDi (None, 20, 9, 9, 128)     73856     \n",
      "_________________________________________________________________\n",
      "time_distributed_184 (TimeDi (None, 20, 9, 9, 128)     147584    \n",
      "_________________________________________________________________\n",
      "time_distributed_185 (TimeDi (None, 20, 4, 4, 128)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_186 (TimeDi (None, 20, 4, 4, 256)     295168    \n",
      "_________________________________________________________________\n",
      "time_distributed_187 (TimeDi (None, 20, 4, 4, 256)     590080    \n",
      "_________________________________________________________________\n",
      "time_distributed_188 (TimeDi (None, 20, 2, 2, 256)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_189 (TimeDi (None, 20, 2, 2, 512)     1180160   \n",
      "_________________________________________________________________\n",
      "time_distributed_190 (TimeDi (None, 20, 2, 2, 512)     2359808   \n",
      "_________________________________________________________________\n",
      "time_distributed_191 (TimeDi (None, 20, 1, 1, 512)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_192 (TimeDi (None, 20, 512)           0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 20, 512)           0         \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 256)               787456    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 5,504,034\n",
      "Trainable params: 5,504,034\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "Creating test generator with 6 samples.Creating train generator with 0 samples.\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Cannot choose from an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-65-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-55-cc0abd09e45d>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    105\u001b[0m     train(data_type, seq_length, model, saved_model=saved_model,\n\u001b[0;32m    106\u001b[0m           \u001b[0mclass_limit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_limit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m           load_to_memory=load_to_memory, batch_size=batch_size, nb_epoch=nb_epoch)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-55-cc0abd09e45d>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(data_type, seq_length, model, saved_model, class_limit, image_shape, load_to_memory, batch_size, nb_epoch)\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             workers=4)\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m                 \u001b[0mgenerator_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'__len__'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    707\u001b[0m                     \u001b[1;34m\"`use_multiprocessing=False, workers > 1`.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m                     \"For more information see issue #1638.\")\n\u001b[1;32m--> 709\u001b[1;33m             \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    642\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mworker\u001b[1;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[1;34m(uid)\u001b[0m\n\u001b[0;32m    624\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mnext\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0muid\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    625\u001b[0m     \"\"\"\n\u001b[1;32m--> 626\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_SHARED_SEQUENCES\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0muid\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-4861ffbf5f76>\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mthreadsafe_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-4861ffbf5f76>\u001b[0m in \u001b[0;36mframe_generator\u001b[1;34m(self, batch_size, train_test, data_type)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m                 \u001b[1;31m# Get a random sample.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m                 \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[1;31m# Check to see if we've already saved this sequence.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\random.py\u001b[0m in \u001b[0;36mchoice\u001b[1;34m(self, seq)\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_randbelow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot choose from an empty sequence'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mseq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Cannot choose from an empty sequence"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
